\documentclass[12pt,a4paper]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage[english,russian]{babel}
\usepackage{indentfirst}
\usepackage{misccorr}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\captionsetup{compatibility=false}
\usepackage{amsmath}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{verbatim}


\def\Rspace{\mathbb{R}}

\begin{document}


\begin{titlepage}
  \begin{center}

    	{ФЕДЕРАЛЬНОЕ ГОСУДАРСТВЕННОЕ БЮДЖЕТНОЕ ОБРАЗОВАТЕЛЬНОЕ УЧРЕЖДЕНИЕ ВЫСШЕГО ОБРАЗОВАНИЯ <<МОСКОВСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ имени М.В. ЛОМОНОСОВА>>}
    \vspace{0.4cm}
    
    {ФИЗИЧЕСКИЙ ФАКУЛЬТЕТ}
    \vspace{0.4cm}
    
    {КАФЕДРА МАТЕМАТИЧЕСКОГО МОДЕЛИРОВАНИЯ И ИНФОРМАТИКИ}
    \vspace{2.0cm}
    
	{БАКАЛАВАРСКАЯ РАБОТА}    
    \vspace{0.4cm}
    
    {\LARGE \textbf{<<КОМПЬЮТЕРНАЯ МОДЕЛЬ РЕМАСШТАБИРОВАНИЯ СЛОЖНЫХ СЦЕН ДЛЯ МОДЕЛЕЙ ПРОЦЕССОВ ПЕРЕНОСА>>}}
  \bigskip
    
\end{center}
\vfill

\hfill\begin{minipage}{0.4\textwidth}
	\begin{flushright}
	Выполнил студент\\
	435 группы\\
	Дейнека Даниил Андреевич\\
		\begin{minipage}{\textwidth}
		\vspace{0.8cm}
		\underline{\hspace{6.2cm}}\\
		\centering
		\small подпись студента
		\end{minipage}
	\end{flushright}
\end{minipage}%
\bigskip
\bigskip

\hfill\begin{minipage}{0.4\textwidth}
	\begin{flushright}
	Научный руководитель\\
	к.т.н., доцент Грачёв Е.А.\\
		\begin{minipage}{\textwidth}
		\vspace{0.8cm}
		\underline{\hspace{6.2cm}}\\
		\centering
		\small подпись научного руководителя
		\end{minipage}
	\end{flushright}
\end{minipage}

\bigskip
\vfill

\begin{minipage}{0.4\textwidth}
	\begin{flushleft}
	Допущена к защите 24.05.18\\
		\vspace{0.3cm}
		Зав.кафедрой\underline{\hspace{3.0cm}}\\
		\centering
		\small подпись зав.кафедрой
	\end{flushleft}
\end{minipage}


\vfill


\begin{center}
  Москва\\
  2018 г.
\end{center}

\end{titlepage}

\tableofcontents

\newpage
\section*{Введение}
\addcontentsline{toc}{section}{Введение}

В некоторых прикладных областях, таких как геологическая разведка и нефтедобыча, существует проблема предсказания некоторого свойства объекта в пространстве по известной точной информации о его локальной структуре — карте признака. Одной из подзадач данной проблемы является ремасштабирование карт признаков.

При переходе на большие масштабы часто возникает ситуация, когда необходимо состыковать несколько карт признаков, чтобы получить одну карту объекта большего размера. Одним из подходов для получения карт является их генерация с помощью нейросетевых методов — в этом случае различные карты признаков получаются независимо друг от друга, из-за чего при их стыковке можно наблюдать резкую границу между ними. В связи с этим данная работа ставит перед собой задачу склейки карт признаков.

Следует отметить, что в данной работе на ставится цель научиться склеивать карты признаков любых объектов. Мы будем рассматривать только "похожие" объекты, те, что обладают одинаковыми статистическими характеристиками. В реальных задачах необходимо состыковать несколько карт признаков одного и того же объекта, но описывающих разные его части; или карты, сгенерированные нейросетями. Тем самым гарантируется, что склеиваемые объекты обладают схожими характеристиками.

При решении рассматриваемой в работе задачи был использованный метод пуассоновского сглаживания, описанный в \cite{Perez} и обобщённый в данной работе на конечномерные карты признаков.

\newpage

\section{Математическая постановка задачи}

Даны две $n$-мерных карт признака, которые пересекаются между собой. Каждую карту можно рассматривать как функцию $n$ переменных, заданной на некоторой области определения. Введём следующие обозначения (см. Рис. \ref{notations}):

$S$ — замкнутое подмножество $\Rspace^n$, область определения одной карты;

$\Omega$ — замкнутое подмножество $S$, область пересечения данных карт;

$\delta\Omega$ — граница множества $\Omega$;

$f : \Rspace^n \longrightarrow \Rspace^1$ — скалярная неизвестная функция, определённая на $\Omega$;

$f^* : \Rspace^n \longrightarrow \Rspace^1$ — скалярная известная функция, определённая на $S$;



\begin{figure}[htbp]
  \centering  
  \includegraphics[width=0.8\textwidth]{images/notations.jpg}
  \caption{Интерполяция $f$ известной функции $f^*$ в области $\Omega$.}\label{notations}
\end{figure}

Одной из интерполяций функции $f$ в области $\Omega$ является мембранная интерполяция, определённая как решение задачи минимизации \cite{Perez}:

\begin{equation}
\min_f \int_\Omega |\nabla f|^2 dV
\end{equation}
с учётом граничных условий Дирихле
\begin{equation}
f|_{\delta\Omega} = f^*_{\delta\Omega}
\end{equation}

Задача вполне определена, однако осталась не использована информация, полученная из накладываемых изображений. Чтобы учесть это, добавим в задачу минимизации некоторое векторное поле:

\begin{equation}\label{min}
\min_f \int_\Omega |\nabla f-\textbf{v}|^2 dV
\end{equation}
\begin{equation}\label{dirichle}
f|_{\delta\Omega} = f^*_{\delta\Omega},
\end{equation}
где $\textbf{v}$ — так называемый вектор \textit{направлений}, который в простейшем случае выбирается равным градиенту одного из изображений. Выбор конкретного вида $\textbf{v}$ будет подробно обсуждён в разделе~\ref{sec:vec}.

Поставленная задача является $n$-мерной вариационной задачей первого порядка. Рассмотрим обобщённый случай такой задачи:
\begin{equation}
	\begin{cases}
		J(f)=\int_\Omega L(x_1,\ldots,x_n,f,f_{x_1},\ldots,f_{x_n})dx_1 \ldots dx_n \\
		f = g, \; (x_1,\ldots,x_n) \in \delta\Omega \\
		\tilde f = \arg\min_f J(f),
	\end{cases}
\end{equation}

где $f_{x_i} = \frac{\partial f}{\partial x_i}, \; i=\overline{1,n}$ и $g$ — некоторая непрерывная функция.

Согласно \cite{Springer}, если функция $f$ является решением многомерной обобщённой вариационной задачи, то она также удовлетворяет уравнению Эйлера-Лагранжа на $\Omega$:
\begin{equation}\label{Euler}
\frac{\partial L}{\partial f} - \sum_{i=1}^n \frac{\partial L_{f_{x_i}}}{\partial x_i} = 0,
\end{equation}

где $L_{f_{x_i}} = \frac{\partial L}{\partial f_{x_i}}, \; i=\overline{1,n}$.

Вернёмся к исходной задаче. Подынтегральная функция
\begin{equation}
L = \left| \nabla f - \textbf{v} \right|^2 = \left( \frac{\partial f}{\partial x_1} - v_{x_1} \right)^2 + \left( \frac{\partial f}{\partial x_2} - v_{x_2} \right)^2 + \ldots + \left( \frac{\partial f}{\partial x_n} - v_{x_n} \right)^2 = 
\end{equation}
\begin{equation}
= \sum_{i=1}^n \left( \frac{\partial f}{\partial x_i} - v_{x_i} \right)^2
\end{equation}
 Вычислим соответствующие частные производные:
\begin{equation}
L_f = \frac{\partial L}{\partial f} = 0
\end{equation}
\begin{equation}
L_{f_{x_i}} = \frac{\partial L}{\partial \left(\frac{\partial f}{\partial x_i} \right)} = 2 \left(\frac{\partial f}{\partial x_i} - v_{x_i} \right), \; i=\overline{1,n}
\end{equation}


Тогда уравнение Эйлера-Лагранжа (\ref{Euler}) примет вид:
\begin{equation}
-2 \frac{\partial}{\partial x_1} \left( \frac{\partial f}{\partial x_1} - v_{x_1} \right) -2 \frac{\partial}{\partial x_2} \left( \frac{\partial f}{\partial x_2} - v_{x_2} \right) - \ldots -2 \frac{\partial}{\partial x_n} \left( \frac{\partial f}{\partial x_n} - v_{x_n} \right) = 0
\end{equation}

\begin{equation}
\left( \frac{\partial^2}{\partial x_1^2} + \frac{\partial^2}{\partial x_2^2} + \ldots + \frac{\partial^2}{\partial x_n^2} \right) f - \left( \frac{\partial v_{x_1}}{\partial x_1} + \frac{\partial v_{x_2}}{\partial x_2} + \ldots + \frac{\partial v_{x_n}}{\partial x_n} \right)= 0
\end{equation}

Вводя оператор Лапласа $$\Delta = \sum_{i=1}^n \frac{\partial^2}{\partial x_i^2}$$ и оператор дивергенции $$div \textbf{v} = \sum_{i=1}^n \frac{\partial v_{x_i}}{\partial x_i}$$ и учитывая полученное соотношение, исходную задачу (\ref{min})-(\ref{dirichle}) можно привести к виду:
\begin{align}
\Delta f = div \textbf{v} \label{poisson}\\
f|_{\delta\Omega} = f^*_{\delta\Omega} \label{dirichle2}
\end{align}

Задача (\ref{poisson})-(\ref{dirichle2}) является уравнением Пуассона с граничными условиями Дирихле. %Далее данная задача дискретизируется и решается численными методами.

\section{Приближение методом конечных разностей}

Вариационная задача (\ref{min})-(\ref{dirichle}) и соответствующее ей уравнение Пуассона (\ref{poisson}) с граничными условиями Дирихле (\ref{dirichle2}) могут быть дискретезированы и решены методом конечных разностей.

Пусть $S,\Omega$ — множества, состоящие из конечного числа точек, определённые на бесконечной дискретной сетке. Отметим, что $S$ может включать все точки карты признака или только часть их них. Для каждого пикселя $p\in S$ определим $2n$ направлений минимизации. Обозначим через $N_p$ множество ближайших соседей по этим направлениям из множества $S$, число которых ограничено $2n$, а также через $\langle p,q \rangle$ обозначим пару точек, где $q \in N_p$. Граница $\Omega$ есть $\delta \Omega = \lbrace p \in S \backslash \Omega : N_p \cap \Omega \neq 0 \rbrace$. $f_p$ — значение $f$ в точке $p$. Тогда задача сводится к расчёту набора интенсивностей $f|_\Omega = \lbrace f_p, p \in \Omega \rbrace$.

Для дискретизации задачи (\ref{min})-(\ref{dirichle}) воспользуемся односторонней аппроксимацией градиента по каждому из направлений минимизации. После подстановки получаем:
\begin{equation}
\begin{cases}
	\min_{f|_\Omega} \sum_{\langle p,q \rangle \cap \Omega \neq 0} \left( f_p - f_q - v_{pq} \right)^2 \\
	f_p = f^*_q, \; \forall p \in \delta \Omega,
\end{cases}
\end{equation}
где $v_{pq}$ — проекция $\textbf{v} \left(\frac{p+q}{2} \right)$ на направление $(p,q)$.

Дискретизация задачи (\ref{poisson}) использует аппроксимацию оператора Лапласа по схеме "крест":

\begin{equation}
\Delta f = \frac{1}{h^2}\sum_{q \in N_p \cap \Omega} \left(f_p - f_q \right) = \frac{1}{h^2} \left( |N_p|f_p - \sum_{q \in N_p \cap \Omega} f_q \right),
\end{equation}
где шаг сетки $h=1$ по всем направлениям, т.к. он соответствует расстоянию между пикселями; $|N_p|$ — число ближайших соседей точки $p$ или, что то же самое, число элементов множества $N_p \cap \Omega$. Для двумерных изображений, где $n=2$, $|N_p| = 4$ во внутренних точках области $\Omega$ и $N_p<4$ — в точках на границе $S$.

После подстановки аппроксимации оператора Лапласа в задачу (\ref{poisson}) и учёта граничных условий (\ref{dirichle2}) получаем систему уравнений:
\begin{equation} \label{discrete}
|N_p|f_p - \sum_{q \in N_p \cap \Omega}f_q = \sum_{q \in N_p \cap \delta \Omega} f^*_q + \sum_{q \in N_p} v_{pq}, \; \forall p \in \Omega
\end{equation}

В тех случаях, когда точка $p$ — внутренняя точка области $\Omega$, то есть $N_p$ целиком содержится в $\Omega$, в правой части уравнения не содержится граничных условий и оно превращается в:
\begin{equation}
|N_p|f_p - \sum_{q \in N_p \cap \Omega}f_q = \sum_{q \in N_p} v_{pq}
\end{equation}

Полученная система является классической системой линейных уравнений вида $Ax = b$. Матрица $A$ является сильно разряженной, симметричной, трёхдиагональной, положительно определённой.

\section{Выбор параметров задачи. Вектор направлений}
\label{sec:vec}

В задаче минимизации (\ref{min}) и уравнении Пуассона (\ref{poisson}) присутствует параметр $\textbf{v}$ — так называемый вектор направлений \cite{Perez}\cite{Matias}. Рассмотрим его более подробно.

Вспомним, что рассматриваемая задача минимизации выглядит следующим образом:
\begin{equation}\label{minv}
\min_f \int_\Omega |\nabla f-\textbf{v}|^2 dV
\end{equation}
\begin{equation}\label{dirichlev}
f|_{\delta\Omega} = f^*_{\delta\Omega},
\end{equation}

\subsection{Метод замены градиента}
Простейший выбор $\textbf{v}$ состоит в том, чтобы выбрать его равным градиенту одной из накладываемых карт:
\begin{equation}
\textbf{v} = \nabla g,
\end{equation}
где $g$ — одно из изображений.

Подставляя в (\ref{minv}), получаем:
\begin{equation}
\min_f \int_\Omega |\nabla f-\textbf{v}|^2 dV = \min_f \int_\Omega |\nabla f-\nabla g|^2 dV
\end{equation}

Уравнение Пуассона (\ref{poisson}) преобразуется следующим образом:
\begin{equation}
\Delta f = div \nabla g = \Delta g
\end{equation}

А дискретизация и соответствующая система линейных уравнений (\ref{discrete}) выглядит следующим образом:
\begin{equation}
|N_p|f_p - \sum_{q \in N_p \cap \Omega}f_q = \sum_{q \in N_p \cap \delta \Omega} f^*_q + \sum_{q \in N_p} \left( g_p - g_q \right), \; \forall p \in \Omega
\end{equation}

Данная задача представляет собой задачу о минимизации разности градиентов искомой карты признаков и одной из накладываемых. Таким образом, решение задачи будет иметь градиент, максимально схожий с градиентом одной из данных карт. Тем самым гарантируется гладкость получаемого изображение на стыке двух карт.

Однако такой подход учитывает градиент лишь одной из накладываемых карт. В случае, когда у одного из изображений на границе присутствуют некоторые характерные особенности, такой выбор $\textbf{v}$ может привести к нежелательным результатам.

\subsection{Метод усреднённого градиента}
Одним из подходов, учитывающих градиенты обеих карт признаков, является метод усреднённого градиента:
\begin{equation}
\textbf{v} = \frac{1}{2} \left( \nabla g_1 + \nabla g_2 \right),
\end{equation}
где $g_1$ и $g_2$ — первая и вторая карта признаков соответственно.

Взяв в качестве вектора направлений $\textbf{v}$ усреднённый градиент обоих изображений, мы сможем получить гладкий переход из одного изображения в другое.

При таком выборе параметра $\textbf{v}$ соответствующие функционал в задаче минимизации (\ref{minv}), уравнение Пуассона (\ref{poisson}) и система линейных уравнений (\ref{discrete}) выглядят следующим образом:
\begin{equation}
\min_f \int_\Omega |\nabla f-\frac{1}{2} \nabla g_1 - \frac{1}{2} \nabla g_2|^2 dV
\end{equation}
\begin{equation}
\Delta f = \frac{1}{2} \Delta g_1 + \frac{1}{2} \Delta g_2
\end{equation}
\begin{equation}
|N_p|f_p - \sum_{q \in N_p \cap \Omega}f_q = \sum_{q \in N_p \cap \delta \Omega} f^*_q + \frac{1}{2}\sum_{q \in N_p} \left( g_{1p} - g_{1q} \right) + \frac{1}{2}\sum_{q \in N_p} \left( g_{2p} - g_{2q} \right), \; \forall p \in \Omega
\end{equation}

\subsection{Метод максимума градиентов}
Другим подходом, учитывающим особенности обеих карт признаков, является метод сохранения максимального значения градиента, где вектор направлений вводится следующим образом:
\begin{equation}
\textbf{v}(x) = \left\lbrace \begin{array}{lr}
\nabla g_1(x), & |g_1(x)| \geq |g_2(x)| \\
\nabla g_2(x), & |g_1(x)| < |g_2(x)|
\end{array} \right.
\end{equation}

Соответствующая дискретизация данного вектора $v_{pq}$ в (\ref{discrete}) выглядит следующим образом:
\begin{equation}
v_{pq} = \left\lbrace \begin{array}{lr}
g_{1p} - g_{1q}, & |g_{1p} - g_{1q}| \geq |g_{2p}-g_{2q}| \\
g_{2p}-g_{2q}, & |g_{1p} - g_{1q}| < |g_{2p}-g_{2q}|
\end{array} \right.
\end{equation}

В данном подходе в векторе $\textbf{v}$ сохраняется информация о скачках градиента в обеих картах признака. Тем самым, на результирующем изображении сохранятся области одинаковой интенсивности с чётко выраженными границами между ними, которые и характеризуются скачками градиента.

\section{Обсуждение результатов}

В этом разделе мы применим полученные алгоритмы по отношению к томографическим изображениям керна.

Как было упомянуто ранее, наша задача заключается в том, чтобы склеивать карты признаков "похожих" объектов. Данные, используемые в следующих подразделах, были получены из одного трёхмерного томографического изображения.

Для двумерных карт были взяты двумерные срезы данного изображения, для трёхмерных карт — трёхмерные срезы. Тем самым гарантируется, что рассматриваемые объекты имеют одинаковую природу и обладают одинаковыми статистическими характеристиками. Данные срезы были выбраны такими, что они не являются соседними и находятся на некотором расстоянии друг от друга. Тем самым, обе карты признаков не коррелируют друг с другом.

Сначала мы ограничимся качественным анализом полученных карт признаков. Затем мы сформулируем математический критерий для оценки качества склейки.


\subsection{Склейка двумерных карт признаков}

Результат работы алгоритма для двумерных карт признаков представлен на Рис. \ref{target1}-\ref{maxgrad1}.

На Рис. \ref{target1} изображены две карты признаков, расположенные рядом друг с другом с небольшим наложением одной поверх второй.
%Область пересечения обозначена красным цветом.
Границу раздела двух изображений можно наблюдать невооружённым глазом.

			\begin{comment}
\begin{figure}[htbp]
\begin{subfigure}{1.0\textwidth}
  \centering  
  \includegraphics[width=0.8\textwidth]{images/target.jpg}
  \caption{}
\end{subfigure}

\begin{subfigure}{1.0\textwidth}
  \centering  
  \includegraphics[width=0.8\textwidth]{images/res.jpg}
  \caption{}
\end{subfigure}
  \caption{Изображения, полученные путём а) — наложения без сглаживания; b) — наложения со сглаживанием.}
\end{figure}
\end{comment}

\begin{figure}[htbp]
  \centering  
  \includegraphics[width=1.0\textwidth]{images/test5_target.png}
  \caption{Изображения, совмещённые друг с другом без сглаживания.} \label{target1}
\end{figure}
\begin{figure}[htbp]
  \centering  
  \includegraphics[width=1.0\textwidth]{images/res_sourcegrad.png}
  \caption{Изображение, сглаженное методом замены градиента градиентом левого изображения.} \label{sourcegrad1}
\end{figure}
\begin{figure}[htbp]
  \centering  
  \includegraphics[width=1.0\textwidth]{images/res_targetgrad.png}
  \caption{Изображение, сглаженное методом замены градиента градиентом правого изображения.} \label{targetgrad1}
\end{figure}
\begin{figure}[htbp]
  \centering  
  \includegraphics[width=1.0\textwidth]{images/test5_ret_average.png}
  \caption{Изображение, сглаженное методом усреднённого градиента.} \label{average1}
\end{figure}
\begin{figure}[htbp]
  \centering  
  \includegraphics[width=1.0\textwidth]{images/res_max.png}
  \caption{Изображение, сглаженное методом максимума градиентов.} \label{maxgrad1}
\end{figure}



На Рис. \ref{sourcegrad1} изображены те же самые карты признаков, но в области их пересечения был применён алгоритм сглаживания методом замены градиента, где параметр $\textbf{v}$ был взят равным градиенту левого изображения. Как можно видеть, граница раздела двух карт была полностью стёрта.

На Рис. \ref{targetgrad1} в качестве параметра $\textbf{v}$ был взят градиент правого изображения. Как и в предыдущем примере, граница раздела двух карт была полностью стёрта. Однако, как можно было ожидать, результаты работы алгоритма немного отличаются. В частности, в центре изображения на близком расстоянии к границе на Рис. \ref{target1} можно наблюдать малую однородную область белого цвета. В результате работы одного алгоритма, эта область полностью исчезла (Рис. \ref{sourcegrad1}), в то время как второй алгоритм сохранил её (Рис. \ref{targetgrad1}). И хотя в данном случае принципиальной разницы между двумя подходами нет, уже можно сделать вывод, что результат зависит от выбора параметра $\textbf{v}$ и, как будет показано далее, в некоторых случаях от этого может зависеть качество сглаживания.

Перейдём теперь к Рис. \ref{average1}, где был применён метод усреднённого градиента. В данном случае результат оказывается несколько смазанным. В частности, малая однородная область белого цвета в центре изображения, которая обсуждалась ранее, после сглаживания изменила свой цвет, став серой. Для томографических изображений значение интенсивности в каждой точке соответствует некоторому значению плотности объекта в соответствующей точке. Изменение значения пикселей в данной области будет соответствовать изменению плотности, а значит после сглаживания данным методом может оказаться, что в рассматриваемом образце присутствуют материалы, не наблюдавшиеся ранее. Таким образом, метод усреднённого градиента является ненадёжным.

И, наконец, результат работы метода максимума градиентов представлен на Рис. \ref{maxgrad1}. Так же, как и в методе замены градиента, граница была полностью стёрта и изображение выглядит гладким, но при этом данный подход учитывает особенности обеих карт признаков. Более того, в отличие от метода усреднённого градиента, в характерных областях однородности не наблюдается существенного изменения значения признака. Таким образом, метод максимума градиентов можно считать наилучшим из рассматриваемых.



\begin{figure}[htbp]
  \centering  
  \includegraphics[width=1.0\textwidth]{images/test6_target.png}
  \caption{Изображения, совмещённые друг с другом без сглаживания.} \label{target2}
\end{figure}
\begin{figure}[htbp]
  \centering  
  \includegraphics[width=1.0\textwidth]{images/test6_ret_sourcegrad.png}
  \caption{Изображение, сглаженное методом замены градиента градиентом левого изображения.} \label{sourcegrad2}
\end{figure}
\begin{figure}[htbp]
  \centering  
  \includegraphics[width=1.0\textwidth]{images/test6_ret_targetgrad.png}
  \caption{Изображение, сглаженное методом замены градиента градиентом правого изображения.} \label{targetgrad2}
\end{figure}
\begin{figure}[htbp]
  \centering  
  \includegraphics[width=1.0\textwidth]{images/test6_ret_average.png}
  \caption{Изображение, сглаженное методом усреднённого градиента.} \label{average2}
\end{figure}
\begin{figure}[htbp]
  \centering  
  \includegraphics[width=1.0\textwidth]{images/test6_ret_mixed.png}
  \caption{Изображение, сглаженное методом максимума градиентов.} \label{maxgrad2}
\end{figure}

Рассмотрим теперь другой пример (Рис. \ref{target2}), где на одном из изображений на границе присутствует характерная однородная область, и посмотрим, как будут выглядеть решения в данной случае.

Изображения, сглаженные методом замены градиента, представлены на Рис. \ref{sourcegrad2} и Рис. \ref{targetgrad2} для градиентов левого и правого изображений соответственно. Как можно заметить, качество сглаживания существенно различается и зависит от выбора вектора $\textbf{v}$. Если во втором случае (Рис. \ref{targetgrad2}) результат в целом можно считать удовлетворительным, то в первом случае (Рис. \ref{sourcegrad2}) однородные области чёрного и белого цветов в центре изображения оказались частично замазаны и после сглаживания выглядят неестественно.

Что касается метода усреднённого градиента (Рис. \ref{average2}), результат по-прежнему является смазанным, как и в предыдущем примере (Рис. \ref{average1}), и является неудовлетворительным по тем же причинам, что и метод замены градиента в одном и случаев, упомянутых выше.

Метод максимума градиентов (Рис. \ref{maxgrad2}), в свою очередь, показывает удовлетворительные результаты и, в отличие от метода замены градиента, не зависит от выбора изображения для вектора $\textbf{v}$.

\subsection{Верификация результатов}

Задача склейки карт признаков заключается в том, чтобы из двух карт признаков, описывающих объекты из одного класса, получить карту объекта большего размера из того же самого класса. Убедимся, что результат действия алгоритма принадлежит тому же классу объектов, что и подающиеся на вход алгоритма изображения.

Как уже было сказано, томографические изображения в предыдущем разделе были взяты из одного и того же трёхмерного изображения, а значит обладают схожими статистическими характеристиками. Будем считать, что карты признаков принадлежат одному классу, если их статистические характеристики "схожи". Выбор рассматриваемых характеристик и критерий "схожести" зависят от конкретной задачи, в рамках которой требуется склейка карт признаков.

Для примера рассмотрим распределение матожиданий строк каждого из изображений. Пусть $f(x, y)$ — значение признака в точке $(x,y)$, которое для рассматриваемых объектов в общем случае является случайной величиной. Тогда мы можем вычислить матожидание этого признака в $j$-й строчке:
\begin{equation}
M(y_j) = \frac{1}{N_1} \sum_{i=1}^{N_1} f(x_i, y_j), \; j = \overline{1,N_2},
\end{equation}
где $N_1$ и $N_2$ — число столбцов и строк в изображении соответственно.

И пусть $p(m)$ есть распределение этой случайной величины. На Рис. \ref{means} изображены три таких распределения: два построены для матожиданий строк оригинальных изображений, которые были совмещены друг с другом с небольшим наложением (Рис. \ref{target1}, $p_1(m)$ — для изображения слева, $p_2(m)$ — для изображения справа); и третье распределение $p_3(m)$ построено для результирующего изображения, сглаженное методом максимума градиентов (Рис. \ref{maxgrad1}). 

\begin{figure}[htbp]
  \centering  
  \includegraphics[width=1.0\textwidth]{images/means2.png}
  \caption{Графики распределения матожиданий строк изображений: $p_1(m)$ — левого оригинального изображения, $p_2(m)$ — правого оригинального изображения, $p_3(m)$ — изображения, склееного методом максимума градиентов.} \label{means}
\end{figure}

Глядя на эти распределения, можно утверждать, что все они похожи друг на друга. Распределение $p_3(m)$ характеризуется более чётко выраженными пиками, что можно объяснить тем, что третье изображение является суммой двух других (если не считать наложения одного на другое и последующего сглаживания), а значит выборка для этого распределения намного больше.

\begin{table}[H]
\caption{\label{tab:means} Матожидания случайных величин, характеризуемых распределениями}
\begin{center}
\begin{tabular}{|c|c|}
\hline
Распределение & Матожидание \\
\hline
$p_1(m)$ & $130.173$ \\
$p_2(m)$ & $132.226$ \\
$p_3(m)$ & $131.718$ \\
\hline
\end{tabular}
\end{center}
\end{table} 

Матожидания случайных величин, характеризуемых данными распределениями, представлены в Таблице \ref{tab:means}. Из данных, приведённых в таблице, можно заключить, что данная статистическая характеристики одинакова для всех трёх изображений и что склейка карт признаков предложенным алгоритмом не выводит карты за пределы их класса, по крайней мере в смысле обладания ими матожиданием с определённым значением.

\subsection{Склейка трёхмерных карт признаков}

Возьмём теперь трёхмерные томографические изображения и склеим их. Ограничимся рассмотрением лишь метода максимума градиентов, так как он даёт наиболее удовлетворительные результаты, как было показано выше для двумерных карт признаков.

На Рис. \ref{target3d} представлены две трёхмерные карт признаков, совмещённые друг с другом с небольшим наложением и нарезанные на три части плоскостями, перпендикулярными границе раздела двух карт, так, чтобы можно было наблюдать внутреннюю часть трёхмерной области.

На Рис. \ref{res3d} представлен результат работы алгоритма. Как можно наблюдать, граница раздела двух карт признака, которая чётко выделяется на Рис. \ref{target3d}, была полностью стёрта и переход из одной карты в другую был сглажен.

Таким образом, было показано, что предложенный алгоритм, сформулированный в общем виде для $n$-мерных карт признаков, работает как для двумерных, так и для трёхмерных карт признаков. 

\begin{figure}[htbp]
\begin{subfigure}{1.0\textwidth}
  \centering  
  \includegraphics[width=0.8\textwidth]{images/slicesnoblending.png}
  \caption{}\label{target3d}
\end{subfigure}

\begin{subfigure}{1.0\textwidth}
  \centering  
  \includegraphics[width=0.8\textwidth]{images/slices.png}
  \caption{}\label{res3d}
\end{subfigure}
  \caption{Срезы трёхмерных карт признаков, полученные путём а) — наложения без сглаживания; b) — наложения со сглаживанием.}
\end{figure}

\newpage

\section*{Вывод}
\addcontentsline{toc}{section}{Вывод}

В результате данной работы был разработан инструмент, позволяющий состыковать несколько конечномерных карт признаков, чтобы получить одну карту объекта большего размера.

Данный инструмент был протестирован на дву- и трёхмерных томографических изображениях керна. На этих данных было проведено качественное сравнение нескольких вариаций предложенного алгоритма: метода замены градиента, метода усреднённого градиента и метода максимума градиента — и был сделан вывод, что последний подход наиболее надёжен, так как он учитывает особенности обеих склеиваемых карт признаков и при этом не изменяет существенно значения признака в области сглаживания.

Было показано, что результат работы предложенного алгоритма принадлежит тому же классу изображений, что и склеиваемые, по крайней мере с точки зрения обладания данных изображений матожиданием с заданным значением.

\section*{Заключение}
\addcontentsline{toc}{section}{Заключение}

Результат данной работы — лишь задел для дальнейших исследований в области ремасштабирования карт признаков.

В дальнейшем планируется сформулировать более точный критерий для оценки качества склейки и применить его к предложенному алгоритму. Затем, убедившись в состоятельности данного инструмента, можно будет приступить непосредственно к решению проблемы ремасштабирования карт признаков.

\begin{thebibliography}{9}
\addcontentsline{toc}{section}{Список литературы}
\bibitem{Perez}P. Perez, M. Gangnet, and A. Blake, Poisson image editing, ACM Transactions on Graphics, 22 (2003), p. 313.
\bibitem{Matias}J. Matías Di Martino, Gabriele Facciolo, and Enric Meinhardt-Llopis, Poisson Image Editing, Image Processing On Line, 6 (2016), pp. 300–325.
\bibitem{Springer}  E. Z. Nonlinear functional analysis and its applications: Variational methods and optimization.
— Springer, 1985. — P. 662.
\end{thebibliography}

\end{document}
